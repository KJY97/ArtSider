# Sub2 Project

> 리뷰 기반 추천 프로젝트



- 필수 라이브러리
  - 데이터 과학 라이브러리
    - Numpy
    - Scipy
    - Scikit-learn



## 컨텐츠 기반 필터링(Content Based Filtering)

> 추천의 대상이 되는 아이템과 사용자에 대한 이해를 바탕으로 추천하는 방식



- 아이템 각각에 대한 이해를 바탕으로 추천하는 방식이므로 아이템의 특성을 뽑아내는 것이 중요



### 컨텐츠 기반 추천 알고리즘 개념 정리

- https://brunch.co.kr/@kakao-it/72
  - 추천 알고리즘 개념 정리
  - CF, CB, 앙상블 기법

- https://www.samsungsemiconstory.com/kr/%EB%B0%B1%EB%B0%9C%EB%B0%B1%EC%A4%91-%EC%B7%A8%ED%96%A5%EC%A0%80%EA%B2%A9%EC%88%98-%EC%B6%94%EC%B2%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%98-%EB%B9%84%EB%B0%80/
  - 콘텐츠 기반 필터링, 협업 필터링 개념 요약



### TF-IDF

> 단어의 빈도를 의미하는 Term Frequency와 문서 빈도(Document Frequency)의 역수인 IDF(Inverse Document Frequency) 합성어로, 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치
>
> 단어들의 중요도를 통해 문서의 핵심어들이나 각 문서가 얼마나 비슷한지 정도를 파악할 수 있다.

- 코사인 유사도

  - 두 벡터 간의 코사인 각도를 이용하여 구할 수 있는 유사도

  - 완전히 동일하면 1, 90도 각도를 이룬다면 0, 반대 방향인 경우 -1

  - 데이터 크기의 차이에 관계없이 유사도 비교 가능

- TF

  - 단어의 빈도(Term Frequency)

  - ```
    tf(t, d) = 문서 d에서 단어 t가 언급된 횟수
    ```

  - 그냥 문서에 단어 갯수를 세면 된다.
  - **단어 빈도가 늘어날 수록 값이 커지므로 이를 보정하기 위해 단어가 언급되었는지만 체크하거나 빈도수에 로그를 취하는 방법으로 수치를 정규화 할 수도 있음**

- IDF

  - 역 문서 빈도

  - DF(문서 빈도)의 역수를 취한 형태

  - 여러 문서들에서 특정 단어의 등장 횟수가 적을수록 그 단어에 가중치가 부여

  - ```
    df(t, D) = 단어 t가 포함된 문서의 수 / 전체 문서(D)의 수
    
    idf(t, D) = 전체 문서의 수 / 단어 t가 포함된 문서의 수
    ```

  - 단어가 몇 번 언급되었는지는 상관 없다. 한 문서에 단어가 한 번이라도 언급되었으면 카운트

  - 특정 단어가 포함된 문서가 없을 때 부모가 0이 되는 이슈도 발생할 수 있으므로 분모에 +작은 값(주로 1)으로 보정한 후 전체 값에 log를 씌워 문제 방지. 로그는 자연로그를 사용

    - 식 수정

    - ```
      idf(t, D) = log(전체 문서의 수 / 1 + 단어 t가 포함된 문서의 수)
      ```

  - 많은 문서에서 언급된 표현들은 최하의 가중치를 받고, 특정 문서에서만 언급된 단어는 높은 가중치를 받는다.

- TF-IDF

  - TF와 IDF를 곱한 값

  - 특정 단어가 한 문서에서 몇 번 언급되었으며, 문서군에서는 얼마나 유니크한가를 표현한 가중치

  - ```
    tf idf(t, d, D) = tf(t, d) * idf(t, D)
    ```

  - 특정 문서에서 언급된 단어들의 가중치를 통해 그 문서의 핵심어를 파악할 수 있으며 나아가 핵심어 들을 통해 각 무서들의 비슷한 정도도 유추할 수 있다.



#### 장점

- 어떤 단어가 중요한 단어인지 직관적으로 해석이 가능하며, 전처리가 잘 수행되었을 때 다른 변수선택/추출보다 좋은 성능을 가지고 있다.

#### 단점

- 제외된 단어들은 학습에 사용되지 않기 때문에 새로운 단어에 대한 해석이 불가
- 순서를 고려하지 않기 때문에 어순에 대한 문법적인 의미를 담고 있지 않음



#### 정리

- 해리포터와 반지의 제왕을 TF-IDF 기법으로 분석한 예시
  - https://blog.naver.com/myincizor/221823805086
    - TF-IDF를 활용하면 특정 문서의 핵심어를 찾을 수 있다.
    - 어떤 문서군을 기준으로 삼느냐에 따라 IDF 가 달라지므로 핵심어도 달라질 수 있다.
    - 이렇게 파악한 핵심어로 어떤 문서가 비슷한지도 유추할 수 있다.
      - 핵심어로 서로 유사도가 높은 문서군을 찾을 수 있음
      - ex) 판타지 소설군에서 해리포터 시리즈의 핵심어는 '해리포터'와 '호그와트'이므로 해리포터 시리즈의 문서들은 서로 유사도가 높게 나올 것임을 아 수 있음



- scikit-learn 에서 제공하는 TF-IDF 함수
  - https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html



- TF-IDF 활용 예시와 시각화 방법 정리
  - https://donghwa-kim.github.io/TFIDF.html



### NLP



#### Word2Vec 텍스트 임베딩 예시

- python을 이용한 콴다 리뷰 분석
  - https://blog.mathpresso.com/python%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%BD%B4%EB%8B%A4-%EB%A6%AC%EB%B7%B0-%EB%B6%84%EC%84%9D-73b3f26e967c



#### Doc2Vec을 사용한 리뷰 감정 분류

- Word2Vec의 일반화

- https://ichi.pro/ko/doc2veceul-sayonghan-libyue-daehan-gamjeong-bunlyu-112200208663350



## 협업 필터링(Collaborative Filtering)

> 사용자의 상품(아이템)에 대한 기록 정보를 바탕으로 특성 벡터를 직접 수치화 하는 것이 아닌 머신 러닝 방식으로 자동적으로 수치화함으로써 각 사용자가 무엇을 좋아할 지를 예측하는 기법



- Memory-Based
  - User-Based
    - 구매 기록 등을 통해 같은 제푸을 구매한 기록이 있는 사용자들을 찾고 이를 바탕으로 아이템을 추천하는 방식
  - Item-Based
    - 사용자를 중심으로 찾는 방식이 아닌 아이템 중심으로 추천하는 방식
- Model-Based
  - User-Item 행렬이 임의의 잠재 요소들을 통해 결정된다는 가정 하에 User-Item 행렬을 User-Latent Featuer 행렬과 Item-Latent Feature 행렬로 분리하고 분리된 각 행렬의 값을 최적화를 통해 알아내는 머신 러닝적 접근ㄴ 방법
  - 어떤 요소가 구ㅐ나 시청, 리뷰 점수로 이어졌는지 파악하기 힘들지만 기록이 어느 정도 쌓였다는 가정 하에 단순 컨텐츠 기반 필터링보다 성능이 크게 개선된 방법



...

...

