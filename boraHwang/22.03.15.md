# 03.15

# 컨텐츠 기반 필터링

## : 사용자와 아이템 각각에 대한 이해를 바탕으로 추천하는 방식

- 아이템의 특성을 뽑아내는 것이 중요

### 영화를 예를 들면

객관적 특성

- 장르
- 감독
- 배우
- 작곡가
- 제작사

주관적 특성

- 관람객의 리뷰
- 관람객의 평점

### 객관적 특성의 경우,

<aside>
💡 메타데이터를 적절히 가공하여 벡터화

</aside>

### 리뷰같은 텍스트 데이터

<aside>
💡 자연어 처리로 핵심 단어들을 찾거나 그 단어를 임베딩

</aside>

### 포스터 같은 이미지, 비디오 데이터를 통해 정보 수집

<aside>
💡 이미지 분석 기법을 활용 딥러닝 모델 사용

</aside>

### 카카오 인공지능 추천 플랫폼

→ TOROS

# TF-IDF

### : 단어의 빈도를 의미하는(TF)와 문서빈도의 역수인 IDF의 합성어로, 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치

→ 단어들의 중요도를 통해 문서의 핵심어/각문서의 유사도를 파악

### 코사인 유사도

: 두 벡터 간의 코사인 각도를 이용하여 구할 수 있는 유사도를 의미, 벡터의 방향이 완전히 동일하면 1, 90도의 각을 이룬다면 0, 반대 방향일 경우 -1

- 데이터의 크기에 차이 없이 유사도를 비교
- 영화 줄거리들의 유사도를 구하는데 효과적

### TF

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d37a77c9-335b-4998-8ee5-730eb8933be6/Untitled.png)

- 위의 공식은 tf를 구하는 아주 기본적인 방식 전체 단어의 개수에서 특정 단어가 몇번 언급되었는지 count하면 됨
- 위의 방식은 특정 단어의 빈도가 늘어날 수록 그 값도 무한대로 커질 수 있다는 특징이 있음
- 이를 보정하기위해 단어가 언급되었는지만 체크하거나, 빈도수에 로그를 취하는 방법으로 수치를 정규화 할 수도 있음

### IDF

: 역 문서 빈도라는 뜻, 문서빈도인 DF의 역수를 취한 형태

- 여러 문서에서 특정 단어의 등장 횟수가 더 적을 수록 그 단어에 가중치가 부여된다는 것을 의미

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/232372c6-6dcf-4b1f-a8af-2671d5e63fc6/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/65490a1c-f0f6-4ba3-a6af-5718f17f0814/Untitled.png)

- IDF를 구할 때, TF와는 다르게 단어가 몇번 언급되었는지는 상관이 없음
- 특정 단어가 한 문서에 등장했으면 +1하면 됨
- IDF를 구할 때 문서의 수가 많아질수록 값이 커지는 문제 발생
- 분모에 +1으로 보정한 후 전체값에 LOG(자연 로그)를 씌워 문제를 방지

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8eb0b37b-bcaf-405a-9eb3-1af94c49703f/Untitled.png)

### TF-IDF

:위의 두 수치를 곱한 값

- 특정 단어가 한 문서에서는 몇번 언급되었으며, 문서군에서는 얼마나 유니크한가를 표현한 가중치
- 그 문서의 핵심어를 파악할 수 있으며
- 그 핵심어로 문서의 비슷한 정도를 유추해 볼 수 있다.

## 결론

줄거리 기반으로 영화 추천 시스템을 구현해 볼 수 있다. 

[인사이저 : 네이버 블로그](https://blog.naver.com/myincizor/221827098614)
